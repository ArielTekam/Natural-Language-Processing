# Natural Language Processing – Task 1 и Task 2

Данный репозиторий содержит задания по курсу обработки естественного языка (NLP), включая:

- Task 1: Векторное представление текста и классификация
- Task 2 Вариант 1: Классификация с использованием Word2Vec
- Task 2 Вариант 2: Реализация семантического аналога команды grep

## Структура репозитория

Natural-Language-Processing/
│
├── task/  # Task 1
│   ├── Извлечение данных из коллекции.ipynb
│   └── entries_results.xls
│
├── task2/  # Task 2 (Вариант 1 и 2)
│   ├── task_2_Вариант_1.ipynb
│   ├── mygrep.py
│   ├── data.txt
│   └── w2v_model.bin  # Модель Word2Vec (Git LFS)
│
└── README.md


## Task 1: Представление текста и классификация

Цель — сравнить несколько способов представления документов:

- TF-IDF  
- Word2Vec (усреднение векторов слов)  
- Комбинация TF-IDF и Word2Vec  

Для классификации используется SVM.  
Лучшие результаты показала комбинация TF-IDF + Word2Vec.

## Task 2 Вариант 1: Классификация на основе Word2Vec

Документ представляется как среднее значение векторов Word2Vec, далее обучается SVM.  
Точность ниже, чем при использовании TF-IDF.

## Task 2 Вариант 2: Семантический grep

Python-скрипт позволяет искать в тексте заданное слово, а также его ближайшие семантические аналоги (по модели Word2Vec).

Пример запуска:

python task2/mygrep.py task2/data.txt "слово"


Программа выводит строки, содержащие искомое слово или его семантически близкие аналоги.

## Используемые технологии

- Python 3  
- gensim (Word2Vec)  
- scikit-learn (TF-IDF, SVM)  
- Jupyter Notebook  
- Git LFS для хранения модели Word2Vec  
