{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b365c838-5807-46f1-b6c1-676b80ded599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество документов: 10000\n",
      "Пример темы: style\n",
      "Пример текста: Парусная гонка Giraglia Rolex Cup пройдет в Средиземном море в 64-й раз. Победители соревнования, проводимого с 1953 года Yacht Club Italiano, помимо других призов традиционно получают в подарок часы  ...\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "path = \"C:/Users/me/news.txt.gz\"  \n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        topic, title, text = parts\n",
    "        labels.append(topic)\n",
    "        texts.append(text)\n",
    "\n",
    "print(\"Количество документов:\", len(texts))\n",
    "print(\"Пример темы:\", labels[0])\n",
    "print(\"Пример текста:\", texts[0][:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806485d2-ea53-4887-84fd-0af2f084b71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natasha in c:\\users\\me\\anaconda3\\lib\\site-packages (1.6.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: razdel in c:\\users\\me\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\me\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\me\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp313-cp313-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: navec>=0.9.0 in c:\\users\\me\\anaconda3\\lib\\site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: slovnet>=0.6.0 in c:\\users\\me\\anaconda3\\lib\\site-packages (from natasha) (0.6.0)\n",
      "Requirement already satisfied: yargy>=0.16.0 in c:\\users\\me\\anaconda3\\lib\\site-packages (from natasha) (0.16.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in c:\\users\\me\\anaconda3\\lib\\site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\me\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\me\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\me\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: click in c:\\users\\me\\anaconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\me\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\me\\anaconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\me\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\me\\appdata\\roaming\\python\\python313\\site-packages (from gensim) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\me\\anaconda3\\lib\\site-packages (from gensim) (1.15.3)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\users\\me\\anaconda3\\lib\\site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\me\\anaconda3\\lib\\site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\me\\appdata\\roaming\\python\\python313\\site-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\me\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading gensim-4.4.0-cp313-cp313-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.4 MB 3.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.6/24.4 MB 4.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 6.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.2/24.4 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.3/24.4 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.4/24.4 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.3/24.4 MB 8.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.1/24.4 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.9/24.4 MB 8.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.5/24.4 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.1/24.4 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.4 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.2/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: smart_open, gensim\n",
      "\n",
      "   ---------------------------------------- 0/2 [smart_open]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   ---------------------------------------- 2/2 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.4.0 smart_open-7.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha razdel pymorphy2 nltk gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df566a73-398d-4308-8c48-46de2c99fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\me\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "C:\\Users\\me\\anaconda3\\Lib\\site-packages\\pymorphy2\\analyzer.py:114: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "from natasha import MorphVocab, NewsMorphTagger, NewsEmbedding, Doc, Segmenter\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Загружаем стоп-слова\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "# Лемматизатор\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# Функция очистки текста\n",
    "def preprocess_text(text):\n",
    "    # 1. Удаляем все, кроме букв\n",
    "    text = re.sub(r'[^а-яА-ЯёЁ ]', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Токенизация\n",
    "    tokens = [t.text for t in tokenize(text)]\n",
    "\n",
    "    # 3. Лемматизация + удаление стоп-слов\n",
    "    lemmas = []\n",
    "    for t in tokens:\n",
    "        if t in russian_stopwords:\n",
    "            continue\n",
    "        p = morph.parse(t)[0].normal_form\n",
    "        if len(p) > 2:            # удаляем слишком короткие слова\n",
    "            lemmas.append(p)\n",
    "\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b8e011-b711-44b5-b3a0-b991f6e8b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово!\n",
      "Пример исходного текста:\n",
      " Парусная гонка Giraglia Rolex Cup пройдет в Средиземном море в 64-й раз. Победители соревнования, проводимого с 1953 года Yacht Club Italiano, помимо других призов традиционно получают в подарок часы  ...\n",
      "\n",
      "После обработки:\n",
      " ['парусный', 'гонка', 'пройти', 'средиземный', 'море', 'победитель', 'соревнование', 'проводить', 'год', 'помимо', 'другой', 'приз', 'традиционно', 'получать', 'подарок', 'часы', 'швейцарский', 'бренд', 'сообщаться', 'пресс']\n",
      "CPU times: total: 6min 32s\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_texts = [preprocess_text(t) for t in texts]\n",
    "\n",
    "print(\"Готово!\")\n",
    "print(\"Пример исходного текста:\\n\", texts[0][:200], \"...\")\n",
    "print(\"\\nПосле обработки:\\n\", processed_texts[0][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47795cc3-a62f-42c0-8d82-cca7a19cea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оставлено документов: 9999\n"
     ]
    }
   ],
   "source": [
    "clean_texts = []\n",
    "clean_labels = []\n",
    "\n",
    "for text, label in zip(processed_texts, labels):\n",
    "    if len(text) > 0:\n",
    "        clean_texts.append(text)\n",
    "        clean_labels.append(label)\n",
    "\n",
    "print(\"Оставлено документов:\", len(clean_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "842561d4-a75f-4ab6-b367-519ae654b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 17836\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# размерность вектора слова\n",
    "VECTOR_SIZE = 200  \n",
    "\n",
    "# Обучаем модель Word2Vec на предобработанных текстах\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=clean_texts,   # список списков лемм\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    window=5,\n",
    "    min_count=5,      # слова реже 5 раз игнорируются\n",
    "    workers=4,\n",
    "    sg=1,             # 1 = skip-gram, 0 = CBOW\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "print(\"Размер словаря:\", len(w2v_model.wv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a6132b9-4f41-48d1-a72f-23090fc67361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова, похожие на: футбол\n",
      "хоккей -> 0.6058688163757324\n",
      "баскетбол -> 0.5930256843566895\n",
      "черчёс -> 0.5888170003890991\n",
      "тарпищев -> 0.5857967138290405\n",
      "фифа -> 0.5799240469932556\n",
      "юношеский -> 0.5776334404945374\n",
      "чемпионат -> 0.5741127729415894\n",
      "мундиаль -> 0.5739104747772217\n",
      "дзюдо -> 0.5661994218826294\n",
      "детско -> 0.5641145706176758\n"
     ]
    }
   ],
   "source": [
    "# Проверим похожие слова для какого-нибудь термина, если он есть в словаре\n",
    "word = \"футбол\"\n",
    "if word in w2v_model.wv:\n",
    "    print(\"Слова, похожие на:\", word)\n",
    "    for w, sim in w2v_model.wv.most_similar(word, topn=10):\n",
    "        print(w, \"->\", sim)\n",
    "else:\n",
    "    print(f\"Слова '{word}' нет в словаре.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d19759-fac5-4ecb-8c62-db7b64d5bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def document_vector_mean(tokens, model):\n",
    "    \"\"\"\n",
    "    Преобразует документ (список лемм) в один вектор,\n",
    "    усредняя векторы всех слов, которые есть в словаре Word2Vec.\n",
    "    \"\"\"\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if not vectors:\n",
    "        # если ни одного слова нет в словаре — возвращаем нулевой вектор\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c684af24-df07-4f8d-9b9b-c2510e9db529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма матрицы признаков: (9999, 200)\n"
     ]
    }
   ],
   "source": [
    "X_mean = np.vstack([document_vector_mean(doc, w2v_model) for doc in clean_texts])\n",
    "y = np.array(clean_labels)\n",
    "\n",
    "print(\"Форма матрицы признаков:\", X_mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6fe736-b473-4971-8db7-3a16bb841d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7999, 200) Test: (2000, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_mean, X_test_mean, y_train, y_test = train_test_split(\n",
    "    X_mean,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # сохраняем пропорции классов\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train_mean.shape, \"Test:\", X_test_mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e78d2d-3336-4d42-9943-c72cf6d24f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность (accuracy), усреднение векторов слов: 0.8405\n",
      "\n",
      "Отчёт по классам:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.68      0.35      0.46        72\n",
      "     culture       0.88      0.93      0.90       279\n",
      "   economics       0.78      0.91      0.84       275\n",
      "      forces       0.80      0.87      0.83       154\n",
      "        life       0.80      0.82      0.81       273\n",
      "       media       0.82      0.80      0.81       295\n",
      "     science       0.86      0.76      0.80       286\n",
      "       sport       0.96      0.97      0.96       288\n",
      "       style       0.89      0.82      0.85        39\n",
      "      travel       0.78      0.64      0.70        39\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.82      0.79      0.80      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Линейное ядро — стандартный вариант для задач классификации текстов\n",
    "svm_mean = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "svm_mean.fit(X_train_mean, y_train)\n",
    "y_pred_mean = svm_mean.predict(X_test_mean)\n",
    "\n",
    "print(\"Точность (accuracy), усреднение векторов слов:\", accuracy_score(y_test, y_pred_mean))\n",
    "print(\"\\nОтчёт по классам:\")\n",
    "print(classification_report(y_test, y_pred_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8bb1622-a8ac-49b1-980a-7cd241f6f4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма TF-IDF матрицы: (9999, 52978)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Преобразуем токенизированные документы обратно в строки\n",
    "docs_for_tfidf = [\" \".join(doc) for doc in clean_texts]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(docs_for_tfidf)\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Форма TF-IDF матрицы:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c1673fe-0518-4f1b-93f7-a3659513914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector_tfidf(doc_index, model, tfidf_matrix, feature_names):\n",
    "    \"\"\"\n",
    "    Строит вектор документа как среднее взвешенное векторов слов\n",
    "    с весами TF-IDF.\n",
    "    \"\"\"\n",
    "    row = tfidf_matrix[doc_index]\n",
    "    indices = row.indices     # индексы слов\n",
    "    data = row.data           # веса TF-IDF\n",
    "\n",
    "    vectors = []\n",
    "    weights = []\n",
    "\n",
    "    for idx, weight in zip(indices, data):\n",
    "        word = feature_names[idx]\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word] * weight)\n",
    "            weights.append(weight)\n",
    "\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    vectors = np.vstack(vectors)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    # среднее взвешенное\n",
    "    return np.sum(vectors * weights[:, None], axis=0) / np.sum(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d714cb26-72a3-42a1-921f-37aa756b1fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма матрицы признаков (TF-IDF + Word2Vec): (9999, 200)\n",
      "Точность (accuracy), TF-IDF + Word2Vec: 0.765\n",
      "\n",
      "Отчёт по классам (TF-IDF + Word2Vec):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.00      0.00      0.00        72\n",
      "     culture       0.79      0.89      0.83       279\n",
      "   economics       0.71      0.91      0.79       275\n",
      "      forces       0.70      0.82      0.75       154\n",
      "        life       0.64      0.79      0.71       273\n",
      "       media       0.75      0.74      0.75       295\n",
      "     science       0.83      0.69      0.75       286\n",
      "       sport       0.96      0.94      0.95       288\n",
      "       style       0.89      0.21      0.33        39\n",
      "      travel       1.00      0.03      0.05        39\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.73      0.60      0.59      2000\n",
      "weighted avg       0.75      0.77      0.74      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\me\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\me\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Строим матрицу признаков\n",
    "X_tfidf = np.vstack([\n",
    "    document_vector_tfidf(i, w2v_model, tfidf_matrix, feature_names)\n",
    "    for i in range(len(clean_texts))\n",
    "])\n",
    "\n",
    "print(\"Форма матрицы признаков (TF-IDF + Word2Vec):\", X_tfidf.shape)\n",
    "\n",
    "# Разбиение на train/test\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    X_tfidf,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Обучаем SVM на новой матрице\n",
    "svm_tfidf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Точность (accuracy), TF-IDF + Word2Vec:\", accuracy_score(y_test_tfidf, y_pred_tfidf))\n",
    "print(\"\\nОтчёт по классам (TF-IDF + Word2Vec):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6dc2e-5c8d-432a-bfc1-892c9801ed99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
